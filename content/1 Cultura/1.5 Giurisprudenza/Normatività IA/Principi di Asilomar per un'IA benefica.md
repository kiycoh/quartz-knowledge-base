---
last modified: 24/10/2025 14:12
tags:
  - intelligenza-artificiale
  - etica-ai
  - sviluppo-agile
---
Più di 100 _thought leaders_ e ricercatori in diverse discipline (economia, legge, etica, filosofia) hanno discusso per formulare i principi di un'[[Intelligenza artificiale|Intelligenza Artificiale]] benefica, orientata al bene dell'umanità.

# I 23 principi di Asilomar
I *23 principi di Asilomar*, sviluppati del 2017, è uno dei primi e più citati insiemi di regole e principi sul governo dell'IA. L'idea era quella di definire come la ricerca sull'IA avrebbe dovuto svilupparsi per garantire all'umanità ulteriori opportunità onde evitare [[Lettura e commenti su IA Act 2024#IA *vietate*|applicazioni dannose o pericolose]].
## La ricerca
1) **Scopo della ricerca:** lo scopo della ricerca sull'Intelligenza Artificiale non dovrebbe essere quello di creare qualsiasi tipo di intelligenza artificiale ma quello di sviluppare l'intelligenza artificiale benefica.

2) **Finanziamento della ricerca:** gli investimenti in Intelligenza Artificiale dovrebbero essere accompagnati da fondi per la ricerca su come assicurarci il loro uso benefico, incluse le spinose questioni che riguardano l'[[informatica]], l'[[economia]], le leggi e i regolamenti, l'[[Etica]] e gli [[studi sociali]], rispondendo a domande del tipo:
	- Come possiamo costruire i sistemi Intelligenza Artificiale del futuro affinché siano molto robusti, cosicché facciano quello che noi vogliamo senza malfunzionamenti o che eventuali attacchi hacker abbiano successo?
	- Come possiamo far crescere la nostra prosperità attraverso l'automazione e contemporaneamente garantire che le persone mantengano le risorse di cui necessitano e uno scopo nella vita?
	- Come possiamo aggiornare i nostri sistemi legali affinché siano più giusti ed efficienti, mantengano il passo con le innovazioni tecnologiche e che sappiano gestire i rischi associati all'Intelligenza Artificiale?
	- A quale insieme di valori dovrebbe essere allineata l'Intelligenza Artificiale e quale stato giuridico e etico dovrebbe avere?

3) Collegamenti tra scienza e politica: dovrebbe esserci un costruttivo e sono scambio tra la ricerca in Intelligenza Artificiale e i politici e i legislatori.

4) Cultura della ricerca: una cultura della cooperazione, della fiducia e della trasparenza dovrebbe essere coltivata all'interno della comunità dei ricercatori e degli sviluppatori che si occupano di Intelligenza Artificiale.

5) Evitare la competizione: le squadre che sviluppano l'Intelligenza Artificiale dovrebbero cooperare attivamente per evitare scorciatoie che aggirino gli standard di sicurezza.

## Etica e valori
6) Sicurezza: I sistemi Intelligenza Artificiale dovrebbero essere protetti e sicuri per tutta la durata del loro ciclo di vita e dovrebbe essere verificabile dove vengono applicati e dove funzionano.

7) Trasparenza dei fallimenti: se un sistema Intelligenza Artificiale causa danni, dovrebbe essere possibile comprenderne il perché.

8) Trasparenza dei giudizi: qualsiasi coinvolgimento di un sistema autonomo in decisioni di carattere giudiziario dovrebbe fornire una spiegazione soddisfacente e verificabile da una autorità umana competente.

9) Responsabilità: i progettisti e i costruttori di sistemi Intelligenza Artificiale avanzati sono coinvolti nelle implicazioni morali derivanti dal loro uso, dal loro abuso e dalle azioni conseguenti al loro sviluppo. Hanno inoltre la possibilità e responsabilità di definire queste implicazioni.

10) Allignamento dei valori: i sistemi Intelligenza Artificiale altamente autonomi dovrebbero essere progettati in modo tale da garantire che i loro scopi e comportamenti siano allineati con i valori umani durante tutto il loro funzionamento.

11) Valori umani: i sistemi Intelligenza Artificiale dovrebbero essere progettati e funzionare in modo tale che siano compatibili con gli ideali della dignità umana, dei diritti, delle libertà e delle diversità culturali.

12) Privacy personale: le persone dovrebbero avere il diritto di accedere, gestire e controllare i dati che generano, limitando di fatto la potenza dei sistemi Intelligenza Artificiale di analizzare e utilizzare quei dati.

13) Libertà e privacy: l'applicazione dell'Intelligenza Artificiale ai dati personali non deve limitare irragionevolmente la libertà, reale o percepita, delle persone.

14) Benefici condivisi: le tecnologie Intelligenza Artificiale dovrebbero portare benefici e aprire nuove possibilità al maggior numero di persone possibile.

15) Prosperità condivisa: la prosperità economica creata dall'Intelligenza Artificiale dovrebbe essere ampiamente condivisa a beneficio di tutta l'umanità.

16) Controllo umano: gli esseri umani dovrebbero scegliere come e se delegare certe decisione ai sistemi Intelligenza Artificiale, con lo scopo di raggiungere obiettivi scelti dagli esseri umani.

17) Non sovversione: il potere conferito dal controllo di sistemi AI altamente avanzati dovrebbe rispettare e migliorare, invece che sovvertire, i processi sociali e civici da cui dipende il benessere della società.

18) Corsa agli armamenti basati sull'Intelligenza Artificiale: qualsiasi corsa agli armamenti basata su armi letali autonome dovrebbe essere scongiurata.

## Questioni a lungo termine
19) Capacità illimitate: non essendoci consenso, dovremmo evitare ipotesi definitive riguardanti il limite massimo delle capacità che l'Intelligenza Artificiale potrebbe raggiungere in futuro.

20) Importanza: l'Intelligenza Artificiale avanzata potrebbe rappresentare un profondo cambiamento nella storia della vita sulla Terra, dovrebbe quindi essere pianificate e gestita con cure e risorse commisurate.

21) Rischi: i rischi derivanti dai sistemi Intelligenza Artificiale, specialmente i rischi catastrofici o esistenziali, devono essere oggetto di pianificazione e sforzi di mitigazione commisurati con il loro impatto che ci si attende.

22) Automiglioramento ricorsivo: i sistemi Intelligenza Artificiale progettati per automigliorarsi ricorsivamente o di autoreplicarsi in modo tale che potrebbero far crescere rapidamente in qualità o in quantità devono essere oggetto di strette misure di sicurezza e controllo.

23) Bene comune: la super-intelligenza dovrebbe essere sviluppata esclusivamente al servizio di ideali etici ampiamente condivisi e a beneficio di tutta l'umanità e non invece di un singolo stato o di una singola organizzazione.